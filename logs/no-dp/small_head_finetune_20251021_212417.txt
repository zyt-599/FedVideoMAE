=== Task: small_head_finetune ===
timestamp: 20251021_212417
config:
experiment: central_weak_finetune_rwf2000
output_dir: FedVideomae_DP/runs/central_weak_finetune_rwf2000_no_dp
seed: 42
data:
  root: FedVideomae_DP/dataset/RWF-2000/train
  val_root: FedVideomae_DP/dataset/RWF-2000/val
  num_frames: 8
  frame_stride: 4
  size: 224
  batch_size: 32
  num_workers: 8
  pin_memory: true
  val_pin_memory: true
  val_batch_size: 16
  aug:
    jitter_b: 0.25
    jitter_c: 0.2
    jitter_s: 0.18
    grayscale_p: 0.15
    erase_p: 0.1
    erase_scale:
    - 0.02
    - 0.08
    erase_ratio:
    - 0.3
    - 3.3
model:
  model_name: MCG-NJU/videomae-base
  pretrained_checkpoint: FedVideomae_DP/runs/pretrain_rwf2000_no_dp/model_final.pth
  head:
    num_classes: 2
    type: mlp
    hidden_dim: 1536
    num_layers: 2
    dropout: 0.2
  peft:
    use_lora: true
    lora_r: 16
    lora_alpha: 32
    lora_dropout: 0.0
    backprop_backbone: false
    train_last_blocks: 0
    target_modules:
    - q_proj
    - k_proj
    - v_proj
    - out_proj
    - fc1
    - fc2
training:
  epochs: 20
  lr: 0.00015
  weight_decay: 0.01
  lr_scheduler: cosine
  clip_grad: 1.0
  use_amp: true
  threshold_scan_metric: f1_macro
  select_best_metric: f1_macro_thr
  weighted_sampler: false
  use_focal: false
  focal_gamma: 1.5
  grad_checkpoint: false
  deterministic: true
  disable_oom_autotune: true
  grad_accum_steps: 2
  min_lr: 1.0e-06
  unfreeze_base: false
  unfreeze_schedule: []
  warmup_epochs: 5
  clear_cache_each_epoch: true
  label_smoothing: 0.0
  class_weights:
  - 1.25
  - 1.0
  mixup:
    enable: false
    alpha: 0.2
    prob: 0.3
    start_after_first_unfreeze: true
    disable_after_epoch: 65
  ema:
    enable: false
    decay: 0.9995
    update_every: 8
  window_adjustments:
  - start_epoch: 45
    end_epoch: 50
    label_smoothing: 0.0
    mixup_prob: 0.2
    ema_decay: 0.995
  - start_epoch: 51
    end_epoch: 55
    label_smoothing: 0.02
    mixup_prob: 0.3
    ema_decay: 0.9995
  - start_epoch: 56
    end_epoch: 100
    class_weights:
    - 1.15
    - 1.0
logging:
  log_every: 20
[Init] Loaded PEFT trainable from checkpoint: matched=200/203
[Init] LoRA fingerprint: keys=200 elems=3145728 sha256=e659bcc43a729c64
[Init] Using pretrained checkpoint: FedVideomae_DP/runs/pretrain_rwf2000_no_dp/model_final.pth | sha256=d7d3936bbfb9d625
[Init] Encoder fingerprint: pos_embed=2b548a93603f7f24 blk0=51dd8e40da9b98b5
[Init] Encoder full-hash: d64e5e502f8232df
[Init] Optim groups: main=3545090 params @ lr=0.00015, bb=0 params @ lr=1e-05
[Init] Trainable params: total=3545090 | lora=0 | head=3545090 | backbone=0
[Val] epoch=1 acc=0.640000 loss=0.654459 f1_macro=0.598930 f1_weighted=0.598930 | thr@f1_macro 0.45/0.698068
[Best] epoch=1 val_best_threshold_score=0.6981 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_no_dp/model_best.pth
[Val] epoch=2 acc=0.695000 loss=0.596935 f1_macro=0.692780 f1_weighted=0.692780 | thr@f1_macro 0.53/0.714936
[Best] epoch=2 val_best_threshold_score=0.7149 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_no_dp/model_best.pth
[Val] epoch=3 acc=0.680000 loss=0.579052 f1_macro=0.648352 f1_weighted=0.648352 | thr@f1_macro 0.42/0.714402
[Val] epoch=4 acc=0.710000 loss=0.532115 f1_macro=0.705015 f1_weighted=0.705015 | thr@f1_macro 0.45/0.744943
[Best] epoch=4 val_best_threshold_score=0.7449 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_no_dp/model_best.pth
[Val] epoch=5 acc=0.700000 loss=0.537975 f1_macro=0.694002 f1_weighted=0.694002 | thr@f1_macro 0.32/0.707082
[Val] epoch=6 acc=0.705000 loss=0.525843 f1_macro=0.702313 f1_weighted=0.702313 | thr@f1_macro 0.36/0.729167
[Val] epoch=7 acc=0.685000 loss=0.525120 f1_macro=0.682708 f1_weighted=0.682708 | thr@f1_macro 0.44/0.724525
[Val] epoch=8 acc=0.670000 loss=0.519788 f1_macro=0.668808 f1_weighted=0.668808 | thr@f1_macro 0.66/0.720869
[Val] epoch=9 acc=0.705000 loss=0.526474 f1_macro=0.700317 f1_weighted=0.700317 | thr@f1_macro 0.56/0.719888
[Val] epoch=10 acc=0.700000 loss=0.527539 f1_macro=0.694843 f1_weighted=0.694843 | thr@f1_macro 0.32/0.730262
[Val] epoch=11 acc=0.735000 loss=0.516526 f1_macro=0.727583 f1_weighted=0.727583 | thr@f1_macro 0.49/0.741629
[Val] epoch=12 acc=0.710000 loss=0.529497 f1_macro=0.703325 f1_weighted=0.703325 | thr@f1_macro 0.33/0.722906
[Val] epoch=13 acc=0.720000 loss=0.524206 f1_macro=0.715187 f1_weighted=0.715187 | thr@f1_macro 0.32/0.719888
[Val] epoch=14 acc=0.720000 loss=0.514605 f1_macro=0.716571 f1_weighted=0.716571 | thr@f1_macro 0.35/0.733169
[Val] epoch=15 acc=0.725000 loss=0.517348 f1_macro=0.721314 f1_weighted=0.721314 | thr@f1_macro 0.36/0.742678
[Val] epoch=16 acc=0.730000 loss=0.513642 f1_macro=0.727273 f1_weighted=0.727273 | thr@f1_macro 0.35/0.732262
[Val] epoch=17 acc=0.720000 loss=0.518293 f1_macro=0.715187 f1_weighted=0.715187 | thr@f1_macro 0.45/0.738325
[Val] epoch=18 acc=0.715000 loss=0.515189 f1_macro=0.710476 f1_weighted=0.710476 | thr@f1_macro 0.47/0.732587
[Val] epoch=19 acc=0.715000 loss=0.514888 f1_macro=0.710476 f1_weighted=0.710476 | thr@f1_macro 0.46/0.738720
[Val] epoch=20 acc=0.715000 loss=0.514742 f1_macro=0.710476 f1_weighted=0.710476 | thr@f1_macro 0.47/0.743144
[Done] finetune completed
