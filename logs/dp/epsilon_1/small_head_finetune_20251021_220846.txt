=== Task: small_head_finetune ===
timestamp: 20251021_220846
config:
experiment: central_weak_finetune_rwf2000
output_dir: FedVideomae_DP/runs/central_weak_finetune_rwf2000_epsilon_1
seed: 42
data:
  root: FedVideomae_DP/dataset/RWF-2000/train
  val_root: FedVideomae_DP/dataset/RWF-2000/val
  num_frames: 8
  frame_stride: 4
  size: 224
  batch_size: 32
  num_workers: 8
  pin_memory: true
  val_pin_memory: true
  val_batch_size: 16
  aug:
    jitter_b: 0.25
    jitter_c: 0.2
    jitter_s: 0.18
    grayscale_p: 0.15
    erase_p: 0.1
    erase_scale:
    - 0.02
    - 0.08
    erase_ratio:
    - 0.3
    - 3.3
model:
  model_name: MCG-NJU/videomae-base
  pretrained_checkpoint: FedVideomae_DP/runs/pretrain_rwf2000_epsilon_1/model_final.pth
  head:
    num_classes: 2
    type: mlp
    hidden_dim: 1536
    num_layers: 2
    dropout: 0.2
  peft:
    use_lora: true
    lora_r: 16
    lora_alpha: 32
    lora_dropout: 0.0
    backprop_backbone: false
    train_last_blocks: 0
    target_modules:
    - q_proj
    - k_proj
    - v_proj
    - out_proj
    - fc1
    - fc2
training:
  epochs: 20
  lr: 0.00015
  weight_decay: 0.01
  lr_scheduler: cosine
  clip_grad: 1.0
  use_amp: true
  threshold_scan_metric: f1_macro
  select_best_metric: f1_macro_thr
  weighted_sampler: false
  use_focal: false
  focal_gamma: 1.5
  grad_checkpoint: false
  deterministic: true
  disable_oom_autotune: true
  grad_accum_steps: 2
  min_lr: 1.0e-06
  unfreeze_base: false
  unfreeze_schedule: []
  warmup_epochs: 5
  clear_cache_each_epoch: true
  label_smoothing: 0.0
  class_weights:
  - 1.25
  - 1.0
  mixup:
    enable: false
    alpha: 0.2
    prob: 0.3
    start_after_first_unfreeze: true
    disable_after_epoch: 65
  ema:
    enable: false
    decay: 0.9995
    update_every: 8
  window_adjustments:
  - start_epoch: 45
    end_epoch: 50
    label_smoothing: 0.0
    mixup_prob: 0.2
    ema_decay: 0.995
  - start_epoch: 51
    end_epoch: 55
    label_smoothing: 0.02
    mixup_prob: 0.3
    ema_decay: 0.9995
  - start_epoch: 56
    end_epoch: 100
    class_weights:
    - 1.15
    - 1.0
logging:
  log_every: 20
[Init] Loaded PEFT trainable from checkpoint: matched=200/203
[Init] LoRA fingerprint: keys=200 elems=3145728 sha256=6731b2ae5ed0138f
[Init] Using pretrained checkpoint: FedVideomae_DP/runs/pretrain_rwf2000_epsilon_1/model_final.pth | sha256=284bbb8ac503d754
[Init] Encoder fingerprint: pos_embed=2b548a93603f7f24 blk0=1dcb5285abbd8781
[Init] Encoder full-hash: 4c4abc746ba4498f
[Init] Optim groups: main=3545090 params @ lr=0.00015, bb=0 params @ lr=1e-05
[Init] Trainable params: total=3545090 | lora=0 | head=3545090 | backbone=0
[Val] epoch=1 acc=0.505000 loss=0.688994 f1_macro=0.418861 f1_weighted=0.418861 | thr@f1_macro 0.45/0.641767
[Best] epoch=1 val_best_threshold_score=0.6418 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_epsilon_1/model_best.pth
[Val] epoch=2 acc=0.620000 loss=0.671482 f1_macro=0.620000 f1_weighted=0.620000 | thr@f1_macro 0.49/0.652489
[Best] epoch=2 val_best_threshold_score=0.6525 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_epsilon_1/model_best.pth
[Val] epoch=3 acc=0.510000 loss=0.674176 f1_macro=0.432279 f1_weighted=0.432279 | thr@f1_macro 0.42/0.667874
[Best] epoch=3 val_best_threshold_score=0.6679 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_epsilon_1/model_best.pth
[Val] epoch=4 acc=0.520000 loss=0.659725 f1_macro=0.438990 f1_weighted=0.438990 | thr@f1_macro 0.44/0.678235
[Best] epoch=4 val_best_threshold_score=0.6782 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_epsilon_1/model_best.pth
[Val] epoch=5 acc=0.575000 loss=0.648940 f1_macro=0.559939 f1_weighted=0.559939 | thr@f1_macro 0.41/0.679153
[Best] epoch=5 val_best_threshold_score=0.6792 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_epsilon_1/model_best.pth
[Val] epoch=6 acc=0.705000 loss=0.651862 f1_macro=0.687756 f1_weighted=0.687756 | thr@f1_macro 0.53/0.710476
[Best] epoch=6 val_best_threshold_score=0.7105 saved=FedVideomae_DP/runs/central_weak_finetune_rwf2000_epsilon_1/model_best.pth
[Val] epoch=7 acc=0.585000 loss=0.656808 f1_macro=0.553655 f1_weighted=0.553655 | thr@f1_macro 0.40/0.666587
[Val] epoch=8 acc=0.700000 loss=0.628119 f1_macro=0.693095 f1_weighted=0.693095 | thr@f1_macro 0.52/0.707632
[Val] epoch=9 acc=0.590000 loss=0.646362 f1_macro=0.571085 f1_weighted=0.571085 | thr@f1_macro 0.42/0.688764
[Val] epoch=10 acc=0.540000 loss=0.652934 f1_macro=0.479873 f1_weighted=0.479873 | thr@f1_macro 0.38/0.696744
[Val] epoch=11 acc=0.550000 loss=0.634359 f1_macro=0.531250 f1_weighted=0.531250 | thr@f1_macro 0.45/0.705996
[Val] epoch=12 acc=0.685000 loss=0.626706 f1_macro=0.669733 f1_weighted=0.669733 | thr@f1_macro 0.52/0.694843
[Val] epoch=13 acc=0.605000 loss=0.635102 f1_macro=0.601403 f1_weighted=0.601403 | thr@f1_macro 0.46/0.684191
[Val] epoch=14 acc=0.630000 loss=0.628241 f1_macro=0.629407 f1_weighted=0.629407 | thr@f1_macro 0.47/0.695680
[Val] epoch=15 acc=0.580000 loss=0.626128 f1_macro=0.554329 f1_weighted=0.554329 | thr@f1_macro 0.43/0.697738
[Val] epoch=16 acc=0.565000 loss=0.624322 f1_macro=0.534747 f1_weighted=0.534747 | thr@f1_macro 0.42/0.694546
[Val] epoch=17 acc=0.565000 loss=0.627794 f1_macro=0.517083 f1_weighted=0.517083 | thr@f1_macro 0.34/0.687197
[Val] epoch=18 acc=0.560000 loss=0.628065 f1_macro=0.519598 f1_weighted=0.519598 | thr@f1_macro 0.42/0.688450
[Val] epoch=19 acc=0.550000 loss=0.627130 f1_macro=0.514615 f1_weighted=0.514615 | thr@f1_macro 0.41/0.690703
[Val] epoch=20 acc=0.555000 loss=0.626864 f1_macro=0.521390 f1_weighted=0.521390 | thr@f1_macro 0.36/0.687197
[Done] finetune completed
